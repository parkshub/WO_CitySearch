{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e09875",
   "metadata": {},
   "source": [
    "# CitySearch Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a25ea6",
   "metadata": {},
   "source": [
    "## Implementation (8/20/24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eff85c",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ff59b",
   "metadata": {},
   "source": [
    "### Navigating to the main page of CitySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.citysearch.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917098d",
   "metadata": {},
   "source": [
    "### Extracting the links to individual cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = driver.find_element(By.CSS_SELECTOR, \"div.cities-container\")\n",
    "cities = container.find_elements(By.CSS_SELECTOR, \"li:not([class*='state']) > a\")\n",
    "\n",
    "city_links = [city.get_attribute(\"href\") for city in cities]\n",
    "state, city = re.search(\"(?<=\\.com\\/).*\", city_links[0]).group().split(\"/\") # extracting state and city name for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e0875f",
   "metadata": {},
   "source": [
    "<img src=\"assets/first.png\" alt=\"Alternative text\" width=\"800\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67c4161",
   "metadata": {},
   "source": [
    "### Navigating to a city link and gathering popular jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddefc5a9",
   "metadata": {},
   "source": [
    "If we have keywords of specific industries we're interested in, I can iterate over them instead of iterating over popular industries. Also, if we have a list of states or cities we're interested in, I can also iterate over those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(city_links[0]) # as an example will be going through the jobs in first city\n",
    "try:\n",
    "    elem = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.categories-wrapper > ul > li > a\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "\n",
    "popular_jobs = driver.find_elements(By.CSS_SELECTOR, 'div.categories-wrapper > ul > li > a')\n",
    "popular_jobs_links = [job.get_attribute(\"href\") for job in popular_jobs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe394a",
   "metadata": {},
   "source": [
    "<img src=\"assets/second.png\" alt=\"Alternative text\" width=\"800\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c0701",
   "metadata": {},
   "source": [
    "### Navigating to first popular job and extracting links to jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(popular_jobs_links[0])\n",
    "\n",
    "try:\n",
    "    elem = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.list-container > div.card > a\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "\n",
    "job_cards = driver.find_elements(By.CSS_SELECTOR, \"div.list-container > div.card > a\")\n",
    "job_cards_links = [job.get_attribute(\"href\") for job in job_cards]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fa1a5",
   "metadata": {},
   "source": [
    "<img src=\"assets/third.png\" alt=\"Alternative text\" width=\"800\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c7c87",
   "metadata": {},
   "source": [
    "### Scraping job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_list = []\n",
    "\n",
    "for i in range(0, 5): #5 should be job_cards_link's length when implemented fully\n",
    "\n",
    "    driver.get(job_cards_links[i])\n",
    "\n",
    "    try:\n",
    "        elem = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.business-details\")))\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "\n",
    "    # not sure if all business have all their contact info so creating a dictionary based on the class name and value\n",
    "    business_details = driver.find_elements(By.CSS_SELECTOR, 'div.business-details > *')\n",
    "\n",
    "    business_details_dict = {\n",
    "        entry.get_attribute(\"class\"): entry.text\n",
    "        for entry in business_details\n",
    "    }\n",
    "\n",
    "    business_list.append(business_details_dict)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c826d2",
   "metadata": {},
   "source": [
    "<img src=\"assets/fourth.png\" alt=\"Alternative text\" width=\"800\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a3c006",
   "metadata": {},
   "source": [
    "### Converting to dataframe, renaming columns and exporting to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a38cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(business_list)\n",
    "\n",
    "df.rename(columns={\n",
    "    \"business-name\": \"business name\",\n",
    "    \"external-links-container\": \"external link\",\n",
    "    \"phone-trigger\": \"phone number\",\n",
    "    \"business-hours\": \"business hours\"\n",
    "}, inplace=True)\n",
    "\n",
    "df.to_csv(f'./{state}_{city}.csv', index=False) # example al_birmingham.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec6b42",
   "metadata": {},
   "source": [
    "#### Possible Improvements and Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfcba80",
   "metadata": {},
   "source": [
    "Depending on the company's needs, I can store these values elsewhere instead of a CSV. Possibly in MongoDB or an SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9ffd9",
   "metadata": {},
   "source": [
    "When scraping large amounts of data, the current script may run into memory issues. During full implementation, I'll refactor the script into something more modular or OOP. Selenium has something called Page Object Model (POM). I'm not too familiar with POM but I am more than willing to try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cffea8",
   "metadata": {},
   "source": [
    "## Implementation (8/26/24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f4588a",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42f664",
   "metadata": {},
   "source": [
    "### Key for converting state name to acronym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\",\n",
    "    \"Northern Mariana Islands\": \"MP\",\n",
    "    \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\",\n",
    "    \"U.S. Virgin Islands\": \"VI\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466671dc",
   "metadata": {},
   "source": [
    "### Importing .xlxs file and filling in merged cells with previous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84108e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"google_maps_keywords.xlsx\")\n",
    "df.loc[:, [\"Country\", \"State\"]] = df.loc[:, [\"Country\", \"State\"]].ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae3ac05",
   "metadata": {},
   "source": [
    "### Opening CitySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.citysearch.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f787893",
   "metadata": {},
   "source": [
    "### Finding container for links of all cities and saving it to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b16c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = driver.find_element(By.CSS_SELECTOR, \"div.cities-container\")\n",
    "cities = container.find_elements(By.CSS_SELECTOR, \"li:not([class*='state']) > a\")\n",
    "city_links = [city.get_attribute(\"href\") for city in cities]\n",
    "state, city = re.search(\"(?<=\\.com\\/).*\", city_links[0]).group().split(\"/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1e598",
   "metadata": {},
   "source": [
    "### Grouping dataframe by country and state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3344fc",
   "metadata": {},
   "source": [
    "During implementation, I would look over all the countries and state. This would be outer most loop. Until implementation, I have hard coded the script to only loop over the cities in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7103bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(\"Country\")\n",
    "grouped_countries = grouped_df.get_group(\"United States\") #todo during implementation, instead of United States, it should be iterated\n",
    "grouped_states = grouped_countries.groupby(\"State\")\n",
    "\n",
    "states = grouped_states.groups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146f49b",
   "metadata": {},
   "source": [
    "### Looping for the states, cities, and industries in that order. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d84365",
   "metadata": {},
   "source": [
    "Some cities didn't have any job postings for some industries, so I've added a TryExcept block to cover for those situations. Currently, it's only looping for the first 5 job postings, but during implementation, the loop would continue until it's extracted everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af9a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    state_cities = grouped_states.get_group(state)[\"City\"]\n",
    "    state_industries = grouped_states.get_group(state)[\"Industry\"]\n",
    "    state_abbrev = us_state_to_abbrev[state]\n",
    "\n",
    "    for city in state_cities:\n",
    "        business_list = []\n",
    "\n",
    "        if (pd.isnull(city)): continue\n",
    "\n",
    "        for industry in state_industries:\n",
    "            if (pd.isnull(industry)): continue\n",
    "\n",
    "            url = f\"https://www.citysearch.com/results?term={industry.strip().replace(' ', '%20')}&where={city.replace(' ', '%20')},%20{state_abbrev}\"\n",
    "            print(\"-------------------------\", url, \"----------------------------\")\n",
    "            driver.get(url)\n",
    "\n",
    "            # extracting all links to jobs in this category\n",
    "            try:\n",
    "                elem = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"div.list-container > div.card > a\")))\n",
    "            except TimeoutException:\n",
    "                print(\"Timed out waiting for page to load: Most likely no job listing in this category\")\n",
    "\n",
    "            job_cards = driver.find_elements(By.CSS_SELECTOR, \"div.list-container > div.card > a\")\n",
    "            job_cards_links = [job.get_attribute(\"href\") for job in job_cards]\n",
    "\n",
    "            # visiting each job link for the current industry and scraping information\n",
    "\n",
    "            if (len(job_cards_links) == 0): continue\n",
    "\n",
    "            # for i in range(len(job_cards_links)): # todo uncomment this when implementing fully\n",
    "            for i in range(5):\n",
    "                print(job_cards_links[i])\n",
    "                driver.get(job_cards_links[i])\n",
    "\n",
    "                try:\n",
    "                    elem = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.business-details\")))\n",
    "                except TimeoutException:\n",
    "                    print(\"Timed out waiting for page to load\")\n",
    "\n",
    "                # not sure if all business have all their contact info so creating a dictionary based on the class name and value\n",
    "                business_details = driver.find_elements(By.CSS_SELECTOR, 'div.business-details > *')\n",
    "\n",
    "                business_details_dict = {\n",
    "                    entry.get_attribute(\"class\"): entry.text\n",
    "                    for entry in business_details\n",
    "                }\n",
    "                business_details_dict[\"industry\"] = industry\n",
    "\n",
    "                business_list.append(business_details_dict)\n",
    "                time.sleep(3)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(business_list)\n",
    "\n",
    "        df.rename(columns={\n",
    "            \"business-name\": \"business name\",\n",
    "            \"external-links-container\": \"external link\",\n",
    "            \"phone-trigger\": \"phone number\",\n",
    "            \"business-hours\": \"business hours\"\n",
    "        }, inplace=True)\n",
    "\n",
    "        df.to_csv(f'./{state_abbrev.lower()}_{city.lower()}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f420cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536cf61d",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e6c95",
   "metadata": {},
   "source": [
    "<img src=\"assets/results.png\" alt=\"Alternative text\" width=\"\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95131f12",
   "metadata": {},
   "source": [
    "#### I think it's ready for full implementation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
