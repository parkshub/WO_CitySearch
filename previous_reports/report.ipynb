{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e09875",
   "metadata": {},
   "source": [
    "# CitySearch Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eff85c",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ff59b",
   "metadata": {},
   "source": [
    "## Navigating to the main page of CitySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.citysearch.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917098d",
   "metadata": {},
   "source": [
    "## Extracting the links to individual cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = driver.find_element(By.CSS_SELECTOR, \"div.cities-container\")\n",
    "cities = container.find_elements(By.CSS_SELECTOR, \"li:not([class*='state']) > a\")\n",
    "\n",
    "city_links = [city.get_attribute(\"href\") for city in cities]\n",
    "state, city = re.search(\"(?<=\\.com\\/).*\", city_links[0]).group().split(\"/\") # extracting state and city name for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e0875f",
   "metadata": {},
   "source": [
    "<img src=\"assets/first.png\" alt=\"Alternative text\" width=\"800\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67c4161",
   "metadata": {},
   "source": [
    "## Navigating to a city link and gathering popular jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddefc5a9",
   "metadata": {},
   "source": [
    "If we have keywords of specific industries we're interested in, I can iterate over them instead of iterating over popular industries. Also, if we have a list of states or cities we're interested in, I can also iterate over those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(city_links[0]) # as an example will be going through the jobs in first city\n",
    "try:\n",
    "    elem = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.categories-wrapper > ul > li > a\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "\n",
    "popular_jobs = driver.find_elements(By.CSS_SELECTOR, 'div.categories-wrapper > ul > li > a')\n",
    "popular_jobs_links = [job.get_attribute(\"href\") for job in popular_jobs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe394a",
   "metadata": {},
   "source": [
    "<img src=\"assets/second.png\" alt=\"Alternative text\" width=\"800\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c0701",
   "metadata": {},
   "source": [
    "## Navigating to first popular job and extracting links to jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(popular_jobs_links[0])\n",
    "\n",
    "try:\n",
    "    elem = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.list-container > div.card > a\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "\n",
    "job_cards = driver.find_elements(By.CSS_SELECTOR, \"div.list-container > div.card > a\")\n",
    "job_cards_links = [job.get_attribute(\"href\") for job in job_cards]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fa1a5",
   "metadata": {},
   "source": [
    "<img src=\"assets/third.png\" alt=\"Alternative text\" width=\"800\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c7c87",
   "metadata": {},
   "source": [
    "## Scraping job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_list = []\n",
    "\n",
    "for i in range(0, 5): #5 should be job_cards_link's length when implemented fully\n",
    "\n",
    "    driver.get(job_cards_links[i])\n",
    "\n",
    "    try:\n",
    "        elem = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.business-details\")))\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "\n",
    "    # not sure if all business have all their contact info so creating a dictionary based on the class name and value\n",
    "    business_details = driver.find_elements(By.CSS_SELECTOR, 'div.business-details > *')\n",
    "\n",
    "    business_details_dict = {\n",
    "        entry.get_attribute(\"class\"): entry.text\n",
    "        for entry in business_details\n",
    "    }\n",
    "\n",
    "    business_list.append(business_details_dict)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c826d2",
   "metadata": {},
   "source": [
    "<img src=\"assets/fourth.png\" alt=\"Alternative text\" width=\"800\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a3c006",
   "metadata": {},
   "source": [
    "## Converting to dataframe, renaming columns and exporting to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a38cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(business_list)\n",
    "\n",
    "df.rename(columns={\n",
    "    \"business-name\": \"business name\",\n",
    "    \"external-links-container\": \"external link\",\n",
    "    \"phone-trigger\": \"phone number\",\n",
    "    \"business-hours\": \"business hours\"\n",
    "}, inplace=True)\n",
    "\n",
    "df.to_csv(f'./{state}_{city}.csv', index=False) # example al_birmingham.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec6b42",
   "metadata": {},
   "source": [
    "### Possible Improvements and Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfcba80",
   "metadata": {},
   "source": [
    "Depending on the company's needs, I can store these values elsewhere instead of a CSV. Possibly in MongoDB or an SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9ffd9",
   "metadata": {},
   "source": [
    "When scraping large amounts of data, the current script may run into memory issues. During full implementation, I'll refactor the script into something more modular or OOP. Selenium has something called Page Object Model (POM). I'm not too familiar with POM but I am more than willing to try!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
